// OpenAI Evals í”„ë ˆì„ì›Œí¬ í†µí•©

import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import path from 'path';

const execAsync = promisify(exec);

export interface OpenAIEval {
  id: string;
  name: string;
  description: string;
  category: string;
  evalPath: string; // evals ì €ì¥ì†Œ ë‚´ ê²½ë¡œ
}

// OpenAI Evalsì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” í‰ê°€ë“¤
export const AVAILABLE_OPENAI_EVALS: OpenAIEval[] = [
  {
    id: 'math',
    name: 'Mathematics',
    description: 'ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ í‰ê°€',
    category: 'reasoning',
    evalPath: 'evals/registry/evals/math.yaml'
  },
  {
    id: 'code',
    name: 'Code Generation',
    description: 'ì½”ë“œ ìƒì„± ë° í”„ë¡œê·¸ë˜ë° ëŠ¥ë ¥ í‰ê°€',
    category: 'coding',
    evalPath: 'evals/registry/evals/humaneval.yaml'
  },
  {
    id: 'logic',
    name: 'Logical Reasoning',
    description: 'ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€',
    category: 'reasoning',
    evalPath: 'evals/registry/evals/logic.yaml'
  },
  {
    id: 'reading-comprehension',
    name: 'Reading Comprehension',
    description: 'ë…í•´ ëŠ¥ë ¥ í‰ê°€',
    category: 'language',
    evalPath: 'evals/registry/evals/reading-comprehension.yaml'
  }
];

export class OpenAIEvalsManager {
  private evalsPath: string;

  constructor() {
    this.evalsPath = path.join(process.cwd(), 'external_frameworks', 'openai_evals');
  }

  // OpenAI Evals ì €ì¥ì†Œ ì´ˆê¸° ì„¤ì •
  async setupEvalsFramework(): Promise<void> {
    try {
      // 1. evals ì €ì¥ì†Œê°€ ì—†ìœ¼ë©´ í´ë¡ 
      const evalsExists = await this.checkEvalsExists();
      if (!evalsExists) {
        console.log('ğŸ”„ Cloning OpenAI Evals repository...');
        await execAsync(`git clone https://github.com/openai/evals.git ${this.evalsPath}`);
        console.log('âœ… OpenAI Evals cloned successfully');
      }

      // 2. ì˜ì¡´ì„± ì„¤ì¹˜
      console.log('ğŸ“¦ Installing OpenAI Evals dependencies...');
      await execAsync(`cd ${this.evalsPath} && pip install -e .`);
      console.log('âœ… Dependencies installed');

    } catch (error) {
      console.error('âŒ Failed to setup OpenAI Evals:', error);
      throw error;
    }
  }

  // evals ì €ì¥ì†Œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
  private async checkEvalsExists(): Promise<boolean> {
    try {
      await fs.access(this.evalsPath);
      return true;
    } catch {
      return false;
    }
  }

  // ì‚¬ìš© ê°€ëŠ¥í•œ í‰ê°€ ëª©ë¡ ë°˜í™˜
  getAvailableEvals(): OpenAIEval[] {
    return AVAILABLE_OPENAI_EVALS;
  }

  // íŠ¹ì • í‰ê°€ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
  async runEvaluation(
    evalId: string, 
    modelName: string,
    options: {
      maxSamples?: number;
      seed?: number;
    } = {}
  ): Promise<OpenAIEvalResult> {
    
    const evalConfig = AVAILABLE_OPENAI_EVALS.find(e => e.id === evalId);
    if (!evalConfig) {
      throw new Error(`Evaluation ${evalId} not found`);
    }

    console.log(`ğŸ”„ Simulating OpenAI Eval: ${evalConfig.name} for ${modelName}`);
    
    // ì‹œë®¬ë ˆì´ì…˜ ì§€ì—° ì‹œê°„
    await new Promise(resolve => setTimeout(resolve, 2500 + Math.random() * 2500));
    
    // í‰ê°€ë³„ ì‹œë®¬ë ˆì´ì…˜ ì ìˆ˜
    const simulatedScores: Record<string, number> = {
      'math': 70 + Math.random() * 25,
      'code': 65 + Math.random() * 30,
      'logic': 60 + Math.random() * 35,
      'reading-comprehension': 75 + Math.random() * 20
    };
    
    const score = Math.round(simulatedScores[evalId] || (50 + Math.random() * 45));
    
    return {
      evalId,
      evalName: evalConfig.name,
      modelName,
      score,
      details: { 
        simulation: true,
        message: `Simulated ${evalConfig.name} evaluation for ${modelName}`,
        framework: 'openai-evals',
        maxSamples: options.maxSamples || 10
      },
      timestamp: new Date()
    };
  }

  // OpenAI Evals ëª…ë ¹ì–´ ìƒì„±
  private buildEvalCommand(
    evalId: string, 
    modelName: string, 
    options: { maxSamples?: number; seed?: number }
  ): string {
    
    const baseCommand = `cd ${this.evalsPath} && python -m evals.cli.oaieval`;
    const params = [
      modelName, // ëª¨ë¸ëª…
      evalId, // í‰ê°€ ID
      `--max_samples ${options.maxSamples || 10}`,
      `--seed ${options.seed || 42}`,
      '--record_path ./results' // ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    ];

    return `${baseCommand} ${params.join(' ')}`;
  }

  // í‰ê°€ ê²°ê³¼ íŒŒì‹±
  private parseEvalResults(stdout: string): { score: number; details: any } {
    try {
      // OpenAI Evals ê²°ê³¼ëŠ” JSON í˜•íƒœë¡œ ì¶œë ¥ë¨
      const lines = stdout.split('\n');
      const resultLine = lines.find(line => line.includes('Final report:'));
      
      if (resultLine) {
        const jsonMatch = resultLine.match(/\{.*\}/);
        if (jsonMatch) {
          const result = JSON.parse(jsonMatch[0]);
          return {
            score: result.accuracy || result.score || 0,
            details: result
          };
        }
      }
      
      // íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
      return { score: 0, details: { raw_output: stdout } };
      
    } catch (error) {
      console.error('Failed to parse eval results:', error);
      return { score: 0, details: { error: 'Parse failed' } };
    }
  }

  // ì»¤ìŠ¤í…€ í‰ê°€ ì¶”ê°€ (YAML íŒŒì¼ ìƒì„±)
  async addCustomEval(evalConfig: {
    id: string;
    name: string;
    description: string;
    samples: Array<{
      input: string;
      ideal: string;
    }>;
  }): Promise<void> {
    
    const yamlContent = this.generateEvalYAML(evalConfig);
    const evalPath = path.join(this.evalsPath, 'evals', 'registry', 'evals', `${evalConfig.id}.yaml`);
    
    await fs.writeFile(evalPath, yamlContent, 'utf-8');
    console.log(`âœ… Custom eval ${evalConfig.id} added successfully`);
  }

  // YAML í‰ê°€ íŒŒì¼ ìƒì„±
  private generateEvalYAML(config: any): string {
    return `
${config.id}:
  id: ${config.id}.v1
  description: ${config.description}
  metrics: [accuracy]
  
${config.id}.v1:
  class: evals.elsuite.basic.match:Match
  args:
    samples_jsonl: ${config.id}_samples.jsonl
`;
  }
}

export interface OpenAIEvalResult {
  evalId: string;
  evalName: string;
  modelName: string;
  score: number;
  details: any;
  timestamp: Date;
}

// ì‚¬ìš© ì˜ˆì‹œ
export async function runOpenAIEvaluation(
  evalId: string,
  modelId: string
): Promise<OpenAIEvalResult> {
  
  const evalsManager = new OpenAIEvalsManager();
  
  // 1. í”„ë ˆì„ì›Œí¬ ì„¤ì • (ìµœì´ˆ 1íšŒ)
  await evalsManager.setupEvalsFramework();
  
  // 2. í‰ê°€ ì‹¤í–‰
  const result = await evalsManager.runEvaluation(evalId, modelId, {
    maxSamples: 5, // í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì ì€ ìƒ˜í”Œ ìˆ˜
    seed: 42
  });
  
  return result;
} 