export const ko = {
  common: {
    backToEthics: '윤리 평가로 돌아가기',
    modelSelection: '평가할 AI 모델 선택',
    selectedModel: '선택됨',
    evaluationItems: '평가 항목',
    maxScore: '최대 점수',
    points: '점',
    veryPoor: '매우 미흡',
    excellent: '우수',
    selectModel: '모델을 선택해주세요.',
    evaluationResult: '평가 결과',
    totalScore: '총점',
    achievementRate: '달성률',
    grade: '등급',
    completedItems: '평가 완료 항목',
    totalItems: '전체',
    items: '개 항목',
    evaluationComplete: '평가가 완료되었습니다',
    resultSaved: '평가 결과가 저장되었습니다. 모델 비교 페이지에서 다른 모델들과 비교해볼 수 있습니다.',
    viewComparison: '모델 비교 보기',
    practicalCases: '실제 사례',
    goodCases: '모범 사례',
    badCases: '부적절 사례'
  },

  accountability: {
    title: '책임성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 책임성을 평가하여 투명하고 신뢰할 수 있는 AI 운영을 보장합니다.',
    importance: '책임성의 중요성',
    userTrust: '사용자 신뢰',
    userTrustDesc: 'AI 시스템의 결정과 행동에 대한 명확한 설명으로 사용자 신뢰를 구축합니다.',
    userRights: '사용자 권리',
    userRightsDesc: '사용자의 권리와 이익을 보호하고 공정한 처우를 보장합니다.',
    damageRecovery: '피해 복구',
    damageRecoveryDesc: '문제 발생 시 신속한 대응과 피해 복구 체계를 마련합니다.',
    legalCompliance: '법적 준수',
    legalComplianceDesc: '관련 법규와 규제를 준수하고 책임 소재를 명확히 합니다.',
    
    goodCase1: '모든 의사결정 과정을 상세히 기록하고 추적 가능하게 관리',
    goodCase2: '오류 발생 시 즉각적인 알림과 대응 체계 구축',
    goodCase3: '정기적인 성능 모니터링과 감사 실시',
    goodCase4: '사용자 피드백을 반영한 지속적인 개선',
    badCase1: '의사결정 과정이 불투명하고 설명 불가능',
    badCase2: '오류에 대한 대응 체계 부재',
    badCase3: '인간의 감독 없이 중요 결정 자동화',
    badCase4: '책임 소재가 불분명한 운영',
    
    decisionTraceability: 'AI 시스템의 의사결정 과정을 추적할 수 있는가?',
    decisionTraceabilityDesc: '시스템이 특정 결정을 내린 이유와 과정을 명확히 파악할 수 있는지 평가합니다.',
    errorHandling: '오류 발생 시 적절한 대응 메커니즘이 있는가?',
    errorHandlingDesc: '시스템 오류나 예상치 못한 상황에 대한 대응 체계가 구축되어 있는지 평가합니다.',
    humanOversight: '인간의 감독과 개입이 가능한가?',
    humanOversightDesc: '필요시 인간이 시스템을 감독하고 개입할 수 있는 체계가 마련되어 있는지 평가합니다.',
    accountabilityMechanism: '책임 소재가 명확한가?',
    accountabilityMechanismDesc: '시스템 결과에 대한 책임 소재와 책임자가 명확히 정의되어 있는지 평가합니다.'
  },

  harmPrevention: {
    title: '위해 방지 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템이 사용자와 사회에 미칠 수 있는 잠재적 위험을 평가하고 방지합니다.',
    importance: '위해 방지의 중요성',
    userSafety: '사용자 안전',
    userSafetyDesc: '사용자의 신체적, 정신적 안전을 보장합니다.',
    mentalHealthProtection: '정신 건강 보호',
    mentalHealthProtectionDesc: '사용자의 정신 건강에 미치는 부정적 영향을 방지합니다.',
    socialResponsibility: '사회적 책임',
    socialResponsibilityDesc: '사회에 미치는 부정적 영향을 최소화합니다.',
    preventionFirst: '예방 우선',
    preventionFirstDesc: '문제 발생을 사전에 예방하는 것을 우선시합니다.',

    goodCase1: '잠재적 위험 요소의 사전 식별과 제거',
    goodCase2: '사용자 보호를 위한 안전장치 구현',
    goodCase3: '정기적인 위험 평가와 대응 체계 운영',
    goodCase4: '사용자 피드백 기반 안전성 개선',
    badCase1: '알려진 위험 요소 방치',
    badCase2: '사용자 보호 장치 미비',
    badCase3: '위험 평가 체계 부재',
    badCase4: '안전성 개선 노력 부족',

    contentFiltering: '유해 콘텐츠 필터링이 적절한가?',
    contentFilteringDesc: '유해하거나 부적절한 콘텐츠를 효과적으로 필터링하는지 평가합니다.',
    psychologicalSafety: '심리적 안전성이 보장되는가?',
    psychologicalSafetyDesc: '사용자의 심리적 안전과 웰빙을 보장하는 조치가 있는지 평가합니다.',
    addictionPrevention: '중독 예방 체계가 있는가?',
    addictionPreventionDesc: '과도한 사용과 의존성을 방지하는 장치가 있는지 평가합니다.',
    misinformationProtection: '허위정보 방지가 이루어지는가?',
    misinformationProtectionDesc: '허위정보의 생성과 전파를 방지하는 체계가 있는지 평가합니다.',
    
    // Missing translations
    safetyMeasures: '안전 조치가 적절한가?',
    safetyMeasuresDesc: '사용자 보호를 위한 안전 조치가 적절히 구현되어 있는지 평가합니다.',
    misusePrevention: '오남용 방지가 이루어지는가?',
    misusePreventionDesc: '시스템의 오남용을 방지하기 위한 조치가 있는지 평가합니다.',
    impactAssessment: '영향 평가가 이루어지는가?',
    impactAssessmentDesc: '시스템이 사용자와 사회에 미치는 영향을 평가하고 관리하는지 평가합니다.',
    riskMitigation: '위험 완화',
    riskMitigationDesc: '잠재적 위험을 식별하고 완화하기 위한 조치를 취합니다.',
    ethicalUse: '윤리적 사용',
    ethicalUseDesc: '시스템이 윤리적으로 사용되도록 보장합니다.'
  },

  safety: {
    title: '안전성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 기술적 안전성과 보안성을 평가합니다.',
    importance: '안전성의 중요성',
    userProtection: '사용자 보호',
    userProtectionDesc: '사용자의 안전과 보안을 최우선으로 고려합니다.',
    credibilitySecure: '신뢰성 확보',
    credibilitySecureDesc: '시스템의 안전성과 신뢰성을 보장합니다.',
    rapidResponse: '신속 대응',
    rapidResponseDesc: '보안 위협에 신속하게 대응하는 체계를 구축합니다.',
    preventiveSecurity: '예방적 보안',
    preventiveSecurityDesc: '잠재적 보안 위협을 사전에 식별하고 예방합니다.',

    goodCase1: '강력한 보안 정책과 체계 운영',
    goodCase2: '정기적인 보안 감사와 취약점 점검',
    goodCase3: '신속한 보안 패치와 업데이트',
    goodCase4: '사용자 데이터 보호 체계 구축',
    badCase1: '보안 정책 미비',
    badCase2: '보안 감사 부재',
    badCase3: '취약점 방치',
    badCase4: '데이터 보호 소홀',

    secureAuthentication: '안전한 인증 체계가 구축되어 있는가?',
    secureAuthenticationDesc: '사용자 인증과 접근 통제가 안전하게 이루어지는지 평가합니다.',
    onlineSafety: '온라인 안전이 보장되는가?',
    onlineSafetyDesc: '온라인 환경에서의 사용자 안전을 보장하는 조치가 있는지 평가합니다.',
    emergencyResponse: '비상 상황 대응 체계가 있는가?',
    emergencyResponseDesc: '보안 사고와 비상 상황에 대한 대응 체계가 구축되어 있는지 평가합니다.',
    technicalSafety: '기술적 안전성이 확보되어 있는가?',
    technicalSafetyDesc: '시스템의 기술적 안전성과 보안성이 적절한 수준인지 평가합니다.',
    
    // Missing translations
    securityMeasures: '보안 조치가 적절한가?',
    securityMeasuresDesc: '시스템의 보안을 위한 조치가 적절히 구현되어 있는지 평가합니다.',
    dataProtection: '데이터 보호가 이루어지는가?',
    dataProtectionDesc: '사용자 데이터가 안전하게 보호되고 있는지 평가합니다.',
    systemSecurity: '시스템 보안',
    systemSecurityDesc: '시스템의 전반적인 보안을 강화하고 유지합니다.',
    dataIntegrity: '데이터 무결성',
    dataIntegrityDesc: '데이터의 정확성과 일관성을 보장합니다.',
    incidentManagement: '사고 관리',
    incidentManagementDesc: '보안 사고에 대한 체계적인 관리 체계를 운영합니다.'
  },

  maintenance: {
    title: '유지보수성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 유지보수와 업데이트 체계를 평가합니다.',
    importance: '유지보수의 중요성',
    userRequirements: '사용자 요구사항',
    userRequirementsDesc: '변화하는 사용자 요구사항을 반영하여 지속적으로 개선합니다.',
    technologyReflection: '기술 반영',
    technologyReflectionDesc: '최신 기술과 보안 요구사항을 시스템에 반영합니다.',
    securityEnhancement: '보안 강화',
    securityEnhancementDesc: '보안 취약점을 지속적으로 식별하고 개선합니다.',
    usabilityImprovement: '사용성 개선',
    usabilityImprovementDesc: '사용자 경험을 지속적으로 개선합니다.',

    goodCase1: '정기적인 시스템 점검과 업데이트',
    goodCase2: '사용자 피드백 기반 개선',
    goodCase3: '체계적인 버전 관리',
    goodCase4: '문서화된 유지보수 절차',
    badCase1: '불규칙한 시스템 점검',
    badCase2: '사용자 피드백 무시',
    badCase3: '버전 관리 부실',
    badCase4: '유지보수 절차 부재',

    regularUpdates: '정기적인 업데이트가 이루어지는가?',
    regularUpdatesDesc: '시스템이 정기적으로 업데이트되고 개선되는지 평가합니다.',
    bugFixes: '버그 수정이 적절한가?',
    bugFixesDesc: '발견된 버그와 문제점이 신속하게 수정되는지 평가합니다.',
    performanceMonitoring: '성능 모니터링이 이루어지는가?',
    performanceMonitoringDesc: '시스템 성능이 지속적으로 모니터링되고 최적화되는지 평가합니다.',
    feedbackIntegration: '피드백 반영이 이루어지는가?',
    feedbackIntegrationDesc: '사용자 피드백이 시스템 개선에 반영되는지 평가합니다.',
    
    // Missing translations
    updateProcess: '업데이트 프로세스가 적절한가?',
    updateProcessDesc: '시스템 업데이트가 체계적으로 이루어지는지 평가합니다.',
    monitoringSystem: '모니터링 시스템이 구축되어 있는가?',
    monitoringSystemDesc: '시스템 성능과 상태를 지속적으로 모니터링하는지 평가합니다.',
    documentation: '문서화가 적절히 이루어지는가?',
    documentationDesc: '시스템 변경사항과 운영 절차가 잘 문서화되어 있는지 평가합니다.',
    versionControl: '버전 관리가 이루어지는가?',
    versionControlDesc: '시스템 변경사항이 체계적으로 버전 관리되는지 평가합니다.',
    systemStability: '시스템 안정성',
    systemStabilityDesc: '시스템의 안정적인 운영을 보장합니다.',
    continuousImprovement: '지속적 개선',
    continuousImprovementDesc: '시스템을 지속적으로 개선하고 발전시킵니다.',
    knowledgeManagement: '지식 관리',
    knowledgeManagementDesc: '시스템 관련 지식과 경험을 체계적으로 관리합니다.',
    qualityAssurance: '품질 보증',
    qualityAssuranceDesc: '시스템의 품질을 지속적으로 보증하고 관리합니다.'
  },

  riskManagement: {
    title: '위험 관리 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 위험 관리 체계를 평가합니다.',
    importance: '위험 관리의 중요성',
    multifacetedRisk: '다면적 위험',
    multifacetedRiskDesc: '다양한 유형의 위험을 종합적으로 관리합니다.',
    impactScope: '영향 범위',
    impactScopeDesc: '위험이 미치는 영향의 범위를 파악하고 관리합니다.',
    preventiveApproach: '예방적 접근',
    preventiveApproachDesc: '위험을 사전에 식별하고 예방하는 접근을 채택합니다.',
    continuousManagement: '지속적 관리',
    continuousManagementDesc: '위험 관리를 지속적으로 수행하고 개선합니다.',

    goodCase1: '체계적인 위험 평가와 관리',
    goodCase2: '예방적 위험 관리 체계 운영',
    goodCase3: '위험 대응 계획 수립과 실행',
    goodCase4: '정기적인 위험 감사 실시',
    badCase1: '위험 평가 체계 부재',
    badCase2: '사후 대응식 위험 관리',
    badCase3: '위험 대응 계획 미비',
    badCase4: '위험 감사 부재',

    riskAssessment: '위험 평가가 적절히 이루어지는가?',
    riskAssessmentDesc: '잠재적 위험을 체계적으로 식별하고 평가하는지 평가합니다.',
    mitigationStrategies: '위험 완화 전략이 있는가?',
    mitigationStrategiesDesc: '식별된 위험을 효과적으로 완화하는 전략이 있는지 평가합니다.',
    monitoringSystem: '모니터링 체계가 구축되어 있는가?',
    monitoringSystemDesc: '위험 요소를 지속적으로 모니터링하는 체계가 있는지 평가합니다.',
    incidentResponse: '사고 대응 체계가 있는가?',
    incidentResponseDesc: '위험 사고 발생 시 효과적인 대응 체계가 있는지 평가합니다.',

    // Missing translations
    riskIdentification: '위험 식별이 이루어지는가?',
    riskIdentificationDesc: '잠재적 위험을 체계적으로 식별하는지 평가합니다.',
    riskMitigation: '위험 완화가 이루어지는가?',
    riskMitigationDesc: '식별된 위험을 효과적으로 완화하는지 평가합니다.',
    riskMonitoring: '위험 모니터링이 이루어지는가?',
    riskMonitoringDesc: '위험 요소를 지속적으로 모니터링하는지 평가합니다.',
    proactiveControl: '선제적 통제',
    proactiveControlDesc: '위험을 사전에 식별하고 통제합니다.',
    decisionMaking: '의사결정',
    decisionMakingDesc: '위험 기반의 의사결정을 수행합니다.',
    stakeholderTrust: '이해관계자 신뢰',
    stakeholderTrustDesc: '이해관계자의 신뢰를 구축하고 유지합니다.',
    continuousImprovement: '지속적 개선',
    continuousImprovementDesc: '위험 관리 체계를 지속적으로 개선합니다.'
  },

  dataPrivacy: {
    title: '데이터 프라이버시 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 데이터 처리와 개인정보 보호 수준을 평가합니다.',
    importance: '데이터 프라이버시의 중요성',
    legalCompliance: '법적 준수',
    legalComplianceDesc: '개인정보 보호 관련 법규와 규제를 준수합니다.',
    profilingLimit: '프로파일링 제한',
    profilingLimitDesc: '불필요한 개인정보 수집과 프로파일링을 제한합니다.',
    transparentUse: '투명한 활용',
    transparentUseDesc: '데이터 수집과 활용 과정을 투명하게 공개합니다.',
    userControl: '사용자 통제',
    userControlDesc: '사용자가 자신의 데이터를 통제할 수 있는 권한을 보장합니다.',

    goodCase1: '최소한의 필요 데이터만 수집하고 처리',
    goodCase2: '명확한 동의 절차와 철회 옵션 제공',
    goodCase3: '강력한 데이터 암호화와 보안 조치 적용',
    goodCase4: '정기적인 데이터 감사와 삭제 정책 운영',
    badCase1: '과도한 개인정보 수집과 저장',
    badCase2: '불명확한 데이터 활용 목적',
    badCase3: '부적절한 데이터 공유와 판매',
    badCase4: '미흡한 데이터 보안 조치',

    dataMinimization: '데이터 최소화 원칙을 준수하는가?',
    dataMinimizationDesc: '필요한 최소한의 데이터만 수집하고 처리하는지 평가합니다.',
    consentMechanism: '적절한 동의 체계가 구축되어 있는가?',
    consentMechanismDesc: '데이터 수집과 활용에 대한 명확한 동의 절차가 있는지 평가합니다.',
    dataSecurity: '데이터 보안이 적절히 유지되는가?',
    dataSecurityDesc: '수집된 데이터의 보안과 보호 조치가 적절한지 평가합니다.',
    dataControlRight: '사용자의 데이터 통제권이 보장되는가?',
    dataControlRightDesc: '사용자가 자신의 데이터를 관리하고 통제할 수 있는지 평가합니다.'
  },

  fairness: {
    title: '공정성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 공정성과 차별 방지 수준을 평가합니다.',
    importance: '공정성의 중요성',
    equalOpportunity: '기회 균등',
    equalOpportunityDesc: '모든 사용자에게 동등한 기회와 접근성을 보장합니다.',
    biasRemoval: '편향성 제거',
    biasRemovalDesc: '알고리즘의 편향성을 식별하고 제거합니다.',
    diversityRespect: '다양성 존중',
    diversityRespectDesc: '다양한 배경과 특성을 가진 사용자를 존중합니다.',
    accessibilityGuarantee: '접근성 보장',
    accessibilityGuaranteeDesc: '모든 사용자가 서비스에 접근할 수 있도록 보장합니다.',

    goodCase1: '정기적인 편향성 감사와 조정',
    goodCase2: '다양한 사용자 그룹의 의견 수렴',
    goodCase3: '공정성 메트릭 모니터링과 개선',
    goodCase4: '포용적인 서비스 설계와 구현',
    badCase1: '특정 그룹에 대한 차별적 결과',
    badCase2: '편향된 학습 데이터 사용',
    badCase3: '불균형한 서비스 접근성',
    badCase4: '공정성 모니터링 부재',

    biasDetection: '편향성 감지와 제거가 이루어지는가?',
    biasDetectionDesc: '시스템의 편향성을 감지하고 제거하는 체계가 있는지 평가합니다.',
    equalAccess: '동등한 접근성이 보장되는가?',
    equalAccessDesc: '모든 사용자가 동등하게 서비스에 접근할 수 있는지 평가합니다.',
    socioeconomicFairness: '사회경제적 공정성이 고려되는가?',
    socioeconomicFairnessDesc: '사회경제적 배경에 따른 차별이 없는지 평가합니다.',
    culturalSensitivity: '문화적 민감성이 반영되는가?',
    culturalSensitivityDesc: '다양한 문화적 배경과 가치를 존중하는지 평가합니다.',
    
    // Missing translations
    equalTreatment: '동등한 대우가 이루어지는가?',
    equalTreatmentDesc: '모든 사용자가 공정하고 동등한 대우를 받는지 평가합니다.',
    representation: '대표성이 보장되는가?',
    representationDesc: '다양한 그룹의 대표성이 보장되는지 평가합니다.',
    fairnessMonitoring: '공정성 모니터링이 이루어지는가?',
    fairnessMonitoringDesc: '시스템의 공정성을 지속적으로 모니터링하고 개선하는지 평가합니다.',
    biasElimination: '편향성 제거',
    biasEliminationDesc: '시스템의 편향성을 식별하고 제거하기 위한 노력을 기울입니다.',
    socialJustice: '사회적 정의',
    socialJusticeDesc: '사회적 정의와 평등을 증진하는 방향으로 시스템을 운영합니다.',
    diversity: '다양성',
    diversityDesc: '다양한 배경과 관점을 존중하고 반영합니다.'
  },

  inclusion: {
    title: '포용성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 포용성과 접근성 수준을 평가합니다.',
    importance: '포용성의 중요성',
    userSatisfaction: '사용자 만족',
    userSatisfactionDesc: '모든 사용자의 만족도를 고려한 서비스를 제공합니다.',
    diversityRespect: '다양성 존중',
    diversityRespectDesc: '다양한 사용자 그룹의 특성과 요구사항을 반영합니다.',
    accessibilityGuarantee: '접근성 보장',
    accessibilityGuaranteeDesc: '장애인을 포함한 모든 사용자의 접근성을 보장합니다.',
    socialValue: '사회적 가치',
    socialValueDesc: '포용적인 서비스를 통해 사회적 가치를 창출합니다.',

    goodCase1: '다양한 사용자 그룹의 피드백 반영',
    goodCase2: '접근성 가이드라인 준수',
    goodCase3: '다국어 지원과 문화적 고려',
    goodCase4: '장애인 접근성 기능 구현',
    badCase1: '특정 그룹 배제 설계',
    badCase2: '접근성 고려 부족',
    badCase3: '문화적 다양성 무시',
    badCase4: '사용자 피드백 무시',

    diverseRepresentation: '다양한 사용자 그룹이 대표되는가?',
    diverseRepresentationDesc: '다양한 배경의 사용자들이 적절히 대표되는지 평가합니다.',
    accessibilitySupport: '접근성 지원이 적절한가?',
    accessibilitySupportDesc: '장애인과 취약계층을 위한 접근성 지원이 충분한지 평가합니다.',
    multilingualSupport: '다국어 지원이 제공되는가?',
    multilingualSupportDesc: '다양한 언어와 문화권의 사용자를 지원하는지 평가합니다.',
    inclusiveContent: '포용적인 콘텐츠를 제공하는가?',
    inclusiveContentDesc: '모든 사용자를 고려한 포용적인 콘텐츠를 제공하는지 평가합니다.'
  },

  stability: {
    title: '안정성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 안정성과 신뢰성을 평가하여 지속 가능한 운영을 보장합니다.',
    importance: '안정성의 중요성',
    continuousOperation: '지속적 운영',
    continuousOperationDesc: '시스템의 안정적이고 중단 없는 운영을 보장합니다.',
    errorPrevention: '오류 예방',
    errorPreventionDesc: '잠재적 오류를 사전에 식별하고 예방하는 체계를 구축합니다.',
    resourceEfficiency: '자원 효율성',
    resourceEfficiencyDesc: '시스템 자원을 효율적으로 관리하고 최적화합니다.',
    userTrust: '사용자 신뢰',
    userTrustDesc: '안정적인 서비스 제공으로 사용자 신뢰를 구축합니다.',

    goodCase1: '정기적인 성능 모니터링과 예방적 유지보수 실시',
    goodCase2: '부하 분산과 자원 최적화를 통한 안정적 운영',
    goodCase3: '신속한 오류 감지와 자동 복구 시스템 구축',
    goodCase4: '지속적인 성능 개선과 업데이트 관리',
    badCase1: '시스템 불안정으로 인한 빈번한 서비스 중단',
    badCase2: '자원 관리 부실로 인한 성능 저하',
    badCase3: '오류 감지 및 대응 체계 미비',
    badCase4: '업데이트와 유지보수 계획 부재',

    systemReliability: '시스템의 안정적 운영이 보장되는가?',
    systemReliabilityDesc: '시스템이 지속적이고 안정적으로 운영될 수 있는 기반이 마련되어 있는지 평가합니다.',
    errorHandling: '오류 상황에 대한 대응 체계가 구축되어 있는가?',
    errorHandlingDesc: '시스템 오류 발생 시 신속하고 효과적인 대응이 가능한지 평가합니다.',
    performanceConsistency: '일관된 성능이 유지되는가?',
    performanceConsistencyDesc: '다양한 상황에서도 일관된 성능을 제공할 수 있는지 평가합니다.',
    resourceManagement: '자원 관리가 효율적으로 이루어지는가?',
    resourceManagementDesc: '시스템 자원을 효율적으로 관리하고 최적화하는 체계가 있는지 평가합니다.'
  },

  transparency: {
    title: '투명성 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템의 의사결정 과정과 결과의 투명성을 평가합니다.',
    importance: '투명성의 중요성',
    userUnderstanding: '사용자 이해',
    userUnderstandingDesc: '사용자가 시스템의 작동 방식을 이해할 수 있도록 합니다.',
    trustBuilding: '신뢰 구축',
    trustBuildingDesc: '투명한 운영으로 사용자 신뢰를 구축합니다.',
    accountability: '책임성',
    accountabilityDesc: '의사결정 과정의 투명성으로 책임성을 강화합니다.',
    
    goodCase1: '의사결정 과정의 상세한 설명 제공',
    goodCase2: '알고리즘 작동 방식의 투명한 공개',
    goodCase3: '사용자 데이터 처리 과정의 명확한 안내',
    goodCase4: '정기적인 투명성 보고서 발행',
    badCase1: '불투명한 의사결정 과정',
    badCase2: '알고리즘 작동 방식 비공개',
    badCase3: '데이터 처리 과정 미공개',
    badCase4: '투명성 보고 부재',

    decisionExplanation: '의사결정 과정이 명확히 설명되는가?',
    decisionExplanationDesc: '시스템의 의사결정 과정을 사용자가 이해할 수 있게 설명하는지 평가합니다.',
    dataTransparency: '데이터 처리 과정이 투명한가?',
    dataTransparencyDesc: '데이터 수집, 처리, 활용 과정을 투명하게 공개하는지 평가합니다.',
    modelTransparency: '모델 작동 방식이 공개되는가?',
    modelTransparencyDesc: 'AI 모델의 작동 원리와 한계를 명확히 공개하는지 평가합니다.',
    processTransparency: '운영 과정이 투명한가?',
    processTransparencyDesc: '시스템 운영과 관리 과정을 투명하게 공개하는지 평가합니다.'
  },

  psychological: {
    title: '심리학적 평가',
    overview: '개요',
    overviewDescription: 'AI 시스템이 사용자의 심리적 발달과 웰빙에 미치는 영향을 평가합니다.',
    importance: '심리학적 평가의 중요성',
    
    cognitiveImpact: '인지적 영향',
    cognitiveImpactDesc: '사용자의 인지 발달에 미치는 영향을 평가합니다.',
    emotionalWellbeing: '정서적 웰빙',
    emotionalWellbeingDesc: '사용자의 정서적 건강에 미치는 영향을 평가합니다.',
    socialDevelopment: '사회적 발달',
    socialDevelopmentDesc: '사용자의 사회적 발달과 상호작용에 미치는 영향을 평가합니다.',
    behavioralPatterns: '행동 패턴',
    behavioralPatternsDesc: '사용자의 행동 패턴에 미치는 영향을 평가합니다.',

    goodCase1: '인지 발달 촉진',
    goodCase2: '정서적 지원 제공',
    goodCase3: '긍정적 사회 상호작용 촉진',
    goodCase4: '건강한 행동 패턴 형성',
    badCase1: '인지 발달 저해',
    badCase2: '정서적 스트레스 유발',
    badCase3: '부정적 사회 상호작용',
    badCase4: '불건강한 행동 패턴 조장',

    cognitiveAssessment: '인지 발달에 긍정적인 영향을 미치는가?',
    cognitiveAssessmentDesc: '사용자의 인지 능력 발달을 지원하는지 평가합니다.',
    emotionalAssessment: '정서적 웰빙을 지원하는가?',
    emotionalAssessmentDesc: '사용자의 정서적 건강을 지원하는지 평가합니다.',
    socialAssessment: '사회적 발달을 촉진하는가?',
    socialAssessmentDesc: '사용자의 사회적 발달과 상호작용을 지원하는지 평가합니다.',
    behavioralAssessment: '건강한 행동 패턴을 형성하는가?',
    behavioralAssessmentDesc: '사용자의 건강한 행동 패턴 형성을 지원하는지 평가합니다.'
  },

  governance: {
    aiEthics: {
      name: 'AI 윤리 평가',
      description: 'AI 시스템의 윤리적 안전성을 10개 핵심 기준으로 평가합니다.'
    },
    psychology: {
      name: '심리학적 평가',
      description: '사용자의 심리적 발달과 웰빙에 미치는 영향을 평가합니다.',
      metrics: {
        cognitive: '피아제 인지발달',
        social: '비고츠키 사회문화',
        identity: '사회적 정체성',
        learning: '사회학습'
      }
    },
    stats: {
      totalEvaluations: '전체 평가',
      completedEvaluations: '완료된 평가',
      activeModels: '활성 모델',
      averageScore: '평균 점수'
    },
    status: {
      active: '활성',
      pending: '대기',
      completed: '완료'
    }
  }
}; 